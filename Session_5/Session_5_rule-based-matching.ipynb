{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from os import path, makedirs, listdir\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from lxml import etree\n",
    "import standoffconverter\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import bodleian_downloader\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "def printmd(string):\n",
    "    display(Markdown(string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why not just regular expressions?\n",
    "\n",
    "- Match on `Doc` objects, not just strings\n",
    "- Match on tokens and token attributes\n",
    "- Use the model's predictions\n",
    "- Example: \"duck\" (verb) vs. \"duck\" (noun)\n",
    "\n",
    "Notes: Compared to regular expressions, the matcher works with Doc and Token\n",
    "objects instead of only strings.\n",
    "\n",
    "It's also more flexible: you can search for texts but also other lexical\n",
    "attributes.\n",
    "\n",
    "You can even write rules that use the model's predictions.\n",
    "\n",
    "For example, find the word \"duck\" only if it's a verb, not a noun.  \n",
    "[(source Ines Montani)](https://raw.githubusercontent.com/ines/spacy-course/master/slides/chapter1_03_rule-based-matching.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Match patterns\n",
    "\n",
    "- Lists of dictionaries, one per token\n",
    "\n",
    "- Match exact token texts\n",
    "\n",
    "```python\n",
    "[{'TEXT': 'iPhone'}, {'TEXT': 'X'}]\n",
    "```\n",
    "\n",
    "- Match lexical attributes\n",
    "\n",
    "```python\n",
    "[{'LOWER': 'iphone'}, {'LOWER': 'x'}]\n",
    "```\n",
    "\n",
    "- Match any token attributes\n",
    "\n",
    "```python\n",
    "[{'LEMMA': 'buy'}, {'POS': 'NOUN'}]\n",
    "```\n",
    "\n",
    "Notes: Match patterns are lists of dictionaries. Each dictionary describes one\n",
    "token. The keys are the names of token attributes, mapped to their expected\n",
    "values.\n",
    "\n",
    "In this example, we're looking for two tokens with the text \"iPhone\" and \"X\".\n",
    "\n",
    "We can also match on other token attributes. Here, we're looking for two tokens\n",
    "whose lowercase forms equal \"iphone\" and \"x\".\n",
    "\n",
    "We can even write patterns using attributes predicted by the model. Here, we're\n",
    "matching a token with the lemma \"buy\", plus a noun. The lemma is the base form,\n",
    "so this pattern would match phrases like \"buying milk\" or \"bought flowers\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iPhone X\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Import the Matcher\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "# Load a model and create the nlp object\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Initialize the matcher with the shared vocab\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Add the pattern to the matcher\n",
    "pattern = [{'TEXT': 'iPhone'}, {'TEXT': 'X'}]\n",
    "matcher.add('IPHONE_PATTERN', None, pattern)\n",
    "\n",
    "# Process some text\n",
    "doc = nlp(\"New iPhone X release date leaked.\")\n",
    "\n",
    "# Call the matcher on the doc\n",
    "matches = matcher(doc)\n",
    "for match_id, start, end in matches:\n",
    "    # Get the matched span\n",
    "    matched_span = doc[start:end]\n",
    "    print(matched_span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Rule-based Matcher Explorer](https://explosion.ai/demos/matcher)\n",
    "![](data:image/jpeg;base64,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)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatically create a list of ministries in George Orwell's *Nineteen eighty-four*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "\n",
    "_1984 = requests.get('http://gutenberg.net.au/ebooks01/0100021.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ministry of Truth',\n",
       " 'Ministry of Love',\n",
       " 'Ministry of Plenty',\n",
       " 'Ministry of Peace',\n",
       " 'Ministry of War']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "pattern = [{\"ORTH\": \"Ministry\"},\n",
    "           {\"LOWER\": \"of\"},\n",
    "           {\"IS_ALPHA\": True},\n",
    "            ]\n",
    "matcher.add(\"ministryof\", None, pattern)\n",
    "\n",
    "doc = nlp(_1984.text)\n",
    "\n",
    "matches = matcher(doc)\n",
    "ministries = []\n",
    "for match_id, start, end in matches:\n",
    "    if str(doc[start:end]) not in ministries:\n",
    "        ministries.append(str(doc[start:end]))\n",
    "ministries    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phrase Matcher for stage directions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, download Shakespeare plays that have annotations for stage directions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0d0edb3fb17470398a9f0f590b4563f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='download and extract xml', max=1, style=Proâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "standoffs = []\n",
    "\n",
    "for fn in tqdm(bodleian_downloader.get_file_descriptors(), desc=\"download and extract xml\"):\n",
    "\n",
    "    tree = etree.fromstring(open(fn, \"rb\").read())\n",
    "\n",
    "    so = standoffconverter.Standoff()\n",
    "    so.from_lxml_tree(tree)\n",
    "\n",
    "    standoffs.append(so)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(standoffs, random_state=4123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_true_stage_directions(standoffs):\n",
    "    stage_directions = []\n",
    "    indices = []\n",
    "    for standoff in standoffs:\n",
    "        indices.append([])\n",
    "        for annotation in standoff.standoffs:\n",
    "            if annotation[\"tag\"] == \"{http://www.tei-c.org/ns/1.0}stage\":\n",
    "                stage_directions.append(standoff.plain[annotation[\"begin\"]:annotation[\"end\"]])\n",
    "                indices[-1].append((annotation[\"begin\"],annotation[\"end\"]))\n",
    "    return stage_directions, indices\n",
    "                \n",
    "train_sd,_ = extract_true_stage_directions(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating some example matchers and validate\n",
    "The validation function also shows you examples of fales matches (false negatives and false positives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bce69394611c45a1a7f426db46288966",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-41-08d2e578daf1>(61)validate_stage_directions()\n",
      "-> print(doc[begin:end])\n",
      "(Pdb) gt\n",
      "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True,  True, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False])\n",
      "(Pdb) len(doc[end])\n",
      "41\n",
      "(Pdb) doc[end]\n",
      "\n",
      "                  \n",
      "                     \n",
      "(Pdb) len(doc[end].text)\n",
      "41\n",
      "(Pdb) q\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-08d2e578daf1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m \u001b[0mvalidate_stage_directions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatcher\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-08d2e578daf1>\u001b[0m in \u001b[0;36mvalidate_stage_directions\u001b[0;34m(matcher, data)\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m                 fp_examples.append({\n\u001b[1;32m     63\u001b[0m                     \u001b[0;34m\"phrase\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-08d2e578daf1>\u001b[0m in \u001b[0;36mvalidate_stage_directions\u001b[0;34m(matcher, data)\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m                 fp_examples.append({\n\u001b[1;32m     63\u001b[0m                     \u001b[0;34m\"phrase\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.4/Frameworks/Python.framework/Versions/3.7/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.4/Frameworks/Python.framework/Versions/3.7/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from spacy.matcher import Matcher\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "\n",
    "pattern = [{'ORTH': 'Enter'},\n",
    "           {'IS_PUNCT': True}]\n",
    "\n",
    "matcher.add('ENTER', None, pattern)\n",
    "\n",
    "\n",
    "pattern = [{'ORTH': 'Enter'},\n",
    "           {'POS': 'PROPN'},\n",
    "           {'IS_PUNCT': True}]\n",
    "\n",
    "matcher.add('ENTER_SOMEONE', None, pattern)\n",
    "\n",
    "pattern = [{'ORTH': 'Exit'},\n",
    "           {'IS_PUNCT': True}]\n",
    "\n",
    "matcher.add('EXIT', None, pattern)\n",
    "\n",
    "pattern = [{'ORTH': 'Exit'},\n",
    "           {'POS': 'PROPN'},\n",
    "           {'IS_PUNCT': True}]\n",
    "\n",
    "matcher.add('EXIT_SOMEONE', None, pattern)\n",
    "\n",
    "\n",
    "def validate_stage_directions(matcher, data):\n",
    "\n",
    "    docs = [nlp(doc.plain) for doc in data]\n",
    "    \n",
    "    data_sd, data_indices = extract_true_stage_directions(data)\n",
    "    \n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    \n",
    "    fn_examples = []\n",
    "    fp_examples = []\n",
    "    \n",
    "    tp_match_names = []\n",
    "    fp_match_names = []\n",
    "    \n",
    "    \n",
    "    for idoc, doc in tqdm(enumerate(docs), total=len(docs)):\n",
    "        \n",
    "        ground_truth = np.zeros(len(doc.text)).astype(bool)\n",
    "        prediction = np.zeros(len(doc.text)).astype(bool)\n",
    "        for begin, end in data_indices[idoc]:\n",
    "            ground_truth[begin:end] = True\n",
    "            \n",
    "        \n",
    "        matches = matcher(doc)\n",
    "        for match_id, begin, end in matches:\n",
    "            prediction[doc[begin].idx:doc[end].idx + len(doc[end])] = True\n",
    "            gt = ground_truth[doc[begin].idx:doc[end].idx + len(doc[end])]\n",
    "            if gt.sum() < len(gt):\n",
    "                fp_examples.append({\n",
    "                    \"phrase\": doc[begin:end].text,\n",
    "                    \"phrase_with_context\":doc[max(0, begin-5):min(len(doc),end+5)].text\n",
    "                })\n",
    "                fp_match_names.append(\n",
    "                    nlp.vocab.strings[match_id]\n",
    "                )\n",
    "            else:\n",
    "                tp_match_names.append(\n",
    "                    nlp.vocab.strings[match_id]\n",
    "                )\n",
    "        \n",
    "        for begin, end in data_indices[idoc]:\n",
    "            if prediction[begin:end].sum() < len(prediction[begin:end]):\n",
    "                fn_examples.append({\n",
    "                    \"phrase\": doc.text[begin:end],\n",
    "                    \"phrase_with_context\":doc.text[max(0,begin-25):min(len(doc.text), end + 25)]\n",
    "                })\n",
    "\n",
    "        tp += np.logical_and(ground_truth, prediction).sum()\n",
    "        fn += np.logical_and(ground_truth, ~prediction).sum()\n",
    "        fp += np.logical_and(~ground_truth, prediction).sum()\n",
    "        tn += np.logical_and(~ground_truth, ~prediction).sum()\n",
    "\n",
    "    precision = tp /(tp + fp) if fp > 0 or tp > 0 else 0\n",
    "    recall = tp /(tp + fn) if tp > 0 or fn > 0 else 0\n",
    "    f1_score = 2*tp / (2*tp + fp + fn) if tp > 0 or fp > 0 or fn > 0 else 0\n",
    "    print(\"precision: {:.2f}, recall: {:.2f}, f1 {:.2f}\".format(precision, recall, f1_score))\n",
    "    \n",
    "    \n",
    "    printmd(\"**What has not been identified? For example:**\")\n",
    "    for ex_dict in np.random.choice(fn_examples, 3):\n",
    "        for k,v in ex_dict.items():\n",
    "            printmd(\"*\" + k + \"*\")\n",
    "            print(\">\", v)\n",
    "    \n",
    "    printmd(\"\\n **What has been identified. although it is not a stage direction? For example:**\")\n",
    "    for ex_dict in np.random.choice(fp_examples, 3):\n",
    "        for k,v in ex_dict.items():\n",
    "            printmd(\"*\" + k + \"*\")\n",
    "            print(\">\", v)\n",
    "            \n",
    "\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,6))\n",
    "    fig.suptitle('how often did a pattern apply?')\n",
    "    \n",
    "    keys, counts = np.unique(tp_match_names, return_counts=True)\n",
    "    ax1.bar(keys,counts)\n",
    "    ax1.set_title(\"correctly applied pattern\")\n",
    "    \n",
    "    keys, counts = np.unique(fp_match_names, return_counts=True)\n",
    "    ax2.bar(keys, counts)\n",
    "    ax2.set_title(\"incorrectly applied pattern\")\n",
    "    \n",
    "    \n",
    "validate_stage_directions(matcher, train[:2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacy",
   "language": "python",
   "name": "spacy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
